{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Getting started\n\nModel-driven registration is a method to remove motion from a series of 2D or \n3D images. It applies specifically to situations where a model exists that can \ndescribe the changes in signal intensity through the series. \n\nThe default engine for coregistration in ``mdreg`` is the package \n``itk-elastix``, but coregistration models from other packages are integrated \nas well (``scikit-image``, ``dipy``). \n\nFor modelling, a number of generic models are built-in, but ``mdreg`` includes \nan interface for integrating custom-built models, or models from any other \npackage. \n\nThis guide illustrates these different types of usage with an example use case, \nthat of fitting the longitudinal MRI relaxation time T1 in the abdomen from a \nLook-Locker MRI sequence. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import packages and data\nLet's start by importing the packages needed in this tutorial. \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport mdreg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``mdreg`` includes a number of test data sets for demonstration purposes. Let's \nfetch the MOLLI example and use ``mdreg``'s built-in plotting tools to \nvisualise the motion:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# fetch the data\ndata = mdreg.fetch('MOLLI')\n\n# We will consider the slice z=0 of the data array:\narray = data['array'][:,:,0,:]\n\n# Use the built-in animation function of mdreg to visualise the motion:\nmdreg.animation(array, vmin=0, vmax=1e4, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using built-in models\n\nThe breathing motion is clearly visible in this slice. Let's use ``mdreg`` to \nremove it. As a starting point, we try ``mdreg`` with default settings.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Perform model-driven coregistration with default settings\ncoreg, defo, fit, pars = mdreg.fit(array, verbose=0)\n\n# # Visualise the results\nmdreg.plot_series(array, fit, coreg, vmin=0, vmax=1e4, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Changing the signal model\nThe default model is a constant, so the model fit (left) does not show any \nchanges. The coregistered image (right) clearly shows the deformations, but \nthey do not have the desired effect. This is not unexpected, because a\nconstant model does not provide a good approximation to the changes in image \ncontrast.\n\nIn this case we are lucky -- the appropriate model for a MOLLI sequence is \n`abs_exp_recovery_2p` and is included in ``mdreg``'s model library. We just \nneed to tell ``mdreg`` which fitting function to use (``'func'``), and \nprovide the keyword arguments required by the model. For this model these are \nthe inversion times TI in units of sec. We define the signal model up front \nso it can be used again later in this script:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "molli = {\n\n    # The function to fit the data\n    'func': mdreg.abs_exp_recovery_2p,\n\n    # The keyword arguments required by the function\n    'TI': np.array(data['TI'])/1000,\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can run ``mdreg`` with this model and check the result again:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Perform model-driven coregistration\ncoreg, defo, fit, pars = mdreg.fit(array, fit_image=molli, verbose=0)\n\n# # Visualise the results\nmdreg.plot_series(array, fit, coreg, vmin=0, vmax=1e4, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This now shows essentially the desired result. The model fit (left) and the \ndeformed image (right) are now both very similar in image contrast to the \noriginal data (middle), but with motion removed. \n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using custom-built models\n\nIn some cases the required model may not be available in the ``mdreg`` \nlibrary, in which case it needs to be custom built. \n\nWe illustrate this idea using the T1-MOLLI model from the ``ukat`` library. \nAll that is needed in order to use it inside ``mdreg`` is to wrap it into a \nfunction that takes the image array as argument, and returns the fit to the \nmodel and the fitted model parameters. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ukat.mapping.t1 import T1\n\ndef ukat_t1_model(array, TI=None, **kwargs):\n    map = T1(np.abs(array), TI, np.eye(4), parameters=2, multithread=False)\n    return map.get_fit_signal(), (map.t1_map, map.m0_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now use this custom model in the same way as built-in models when we \nrun ``mdreg``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the fit function and its arguments\nukat_model = {\n    'func': ukat_t1_model,\n    'TI': np.array(data['TI']),\n}\n\n# Perform model-driven coregistration\ncoreg, defo, fit, pars = mdreg.fit(array, fit_image=ukat_model, verbose=0)\n\n# Visualise the results\nmdreg.plot_series(array, fit, coreg, vmin=0, vmax=1e4, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the result is the same as before using the built-in model \n``abs_exp_recovery_2p``.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pixel-by-pixel fitting\n\nIn cases where the model is not available in any existing package, or the \nuser is not prepared to import an existing package, the fit function must be \nwritten from scratch. In general, ``mdreg`` only requires that it has the \nsame interface as the `ukat_t1_model` defined above: one argument (the image \narray), any number of keyword arguments, and two return values (the model fit \nand the fit parameters).\n\n``mdreg`` offers a convenient shortcut for the common scenario where a 1D \nsignal model is applied for each pixel independently (*pixel-by-pixel \nfitting*). All that is needed is to define the 1D model explicitly. \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def my_pixel_model(xdata, S0, T1, **kwargs):\n    return np.abs(S0 * (1 - 2 * np.exp(-xdata/T1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optionally, one may also provide a function that derives initial values from \nthe data and any constant initial values provided by the user.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def my_pixel_model_init(xdata, ydata, p0):\n    S0 = np.amax(np.abs(ydata))\n    return [S0*p0[0], p0[1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With these definitions in hand, a pixel model fit can be defined as a \ndictionary specifying the model, its parameters (xdata), and any optional \narguments.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_pixel_fit = {\n\n    # The custom-built single pixel model\n    'model': my_pixel_model,\n\n    # xdata for the single-pixel model\n    'xdata': np.array(data['TI'])/1000,\n\n    # Optional: custom-built initialization function\n    'func_init': my_pixel_model_init,\n\n    # Optional: initial values for the free parameters\n    'p0': [1,1.3], \n\n    # Optional: bounds for the free model parameters\n    'bounds': (0, np.inf),\n\n    # Optional: any keyword arguments accepted by scipy's curve_fit\n    'xtol': 1e-3,\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And this can be provided directly to ``mdreg.fit`` via the keyword argument \n``fit_pixel`` - instructing ``mdreg`` to perform pixel-based fitting using \nthe parameters defined in ``my_pixel_fit``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Perform model-driven coregistration with a custom pixel model\ncoreg, defo, fit, pars = mdreg.fit(array, fit_pixel=my_pixel_fit, verbose=0)\n\n# Visualise the results\nmdreg.plot_series(array, fit, coreg, vmin=0, vmax=1e4, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the result is the same as before using the built-in model \n``abs_exp_recovery_2p`` and the ukat implementation ``ukat_t1_model``.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Customizing the coregistration\n\nIn the above examples we have not provided any detail on the coregistration \nitself, which means that the default in ``mdreg`` has been applied. This is \nthe standard b-spline coregistration of elastix, but modified to use a \nleast-squares metric rather than mutual information. The detailed default \nparameter settings can be found in the function ``mdreg.elastix.params``.\n\nWe can try to improve the result further by customizing the coregistration \nmodel rather than using the default. This can be done either by modifying the\n``elastix`` parameters, or by using another coregistration package supported \nby ``mdreg`` (currently only ``skimage`` available).\n\n## Customizing elastix coregistration\n\nTo illustrate customizing the ``elastix`` parameters, we perform ``mdreg`` \nwith a more fine-grained deformation field. The default coregistration uses \na grid spacing of 5cm, which is relatively coarse, so we will try a finer \ndeformation of 5mm. In order to do that, we need to provide the actual pixel \nspacing of the data, and modify default elastix parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "deform5mm = {\n\n    # Pixel spacing in the images\n    'spacing': data['pixel_spacing'],\n\n    # Default elastix parameters with custom grid spacing\n    'params': mdreg.elastix.params(FinalGridSpacingInPhysicalUnits= \"5.0\"),\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We run ``mdreg`` again with the correct signal model, but now using the 5mm \ncoregistration:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Perform model-driven coregistration\ncoreg, defo, fit, pars = mdreg.fit(array, fit_image=molli, fit_coreg=deform5mm, verbose=0)\n\n# Visualise the results\nmdreg.plot_series(array, fit, coreg, vmin=0, vmax=1e4, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The effect of the finer deformations is apparent, but it has not \nfundamentally improved the result. In fact, it has created smaller unphysical\ndeformations that have blurred out some of the anatomical features. An \nexample is the small cyst in the upper pole of the right kidney, which is \nclearly visible in the data but can no longer be seen in the model fit. The \nexample illustrates that the grid spacing is a critical parameter and should \nbe chosen to reflect the scale of the expected deformations. \n\nAny coregistration method available in elastix can be used in the same way by\nproviding a custom set of elstix parameters.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Coregistration with ``skimage``\n\nWhile ``skimage`` is the default package for coregistration, ``mdreg`` also \nhas an option to use coregistration modules from the package ``scikit-image``. \n\nFor this illustration we run skimage coregistration with default parameters, \nexcept for the attachment which is increased to 30 (default=15) to allow for \nfiner deformations.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "attach30 = {\n\n    # The package needs to be defined if it is not elastix\n    'package': 'skimage',\n\n    # Use default parameters except for the attachment\n    'params': mdreg.skimage.params(attachment=30)\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run ``mdreg`` again with the correct signal model, but now using the \ncustomized ``skimage`` coregistration:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Perform model-driven coregistration\ncoreg, defo, fit, pars = mdreg.fit(array, fit_image=molli, fit_coreg=attach30, verbose=0)\n\n# Visualise the results\nmdreg.plot_series(array, fit, coreg, vmin=0, vmax=1e4, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This result shows good coregistration results, in this case better preserving \nfine grain features such as kidney cysts in comparison to the default elastix \nimplementation.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}